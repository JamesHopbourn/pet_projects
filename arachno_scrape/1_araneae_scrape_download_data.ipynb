{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_simple(url, strain_name=None, strain_attrs=None):\n",
    "    response = requests.get(url)#, headers=headers, proxies=proxies)\n",
    "    if strain_name is None and strain_attrs is None:\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "    elif strain_attrs is None:\n",
    "        strainer = SoupStrainer(strain_name)\n",
    "        soup = BeautifulSoup(response.text, 'lxml', parse_only=strainer)\n",
    "    else:\n",
    "        strainer = SoupStrainer(strain_name, strain_attrs)\n",
    "        soup = BeautifulSoup(response.text, 'lxml', parse_only=strainer)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://arachno.piwigo.com/'\n",
    "families_url = base_url + 'index?/category/familles'\n",
    "\n",
    "main_page = get_soup_simple(families_url, 'li', {'class':'selected liOpen'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48408763b51c41a8b2aa8c6d7e691278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1519.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agelenidae</td>\n",
       "      <td>Agelena</td>\n",
       "      <td>Agelena agelenoides</td>\n",
       "      <td>https://arachno.piwigo.com/index?/category/176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agelenidae</td>\n",
       "      <td>Agelena</td>\n",
       "      <td>Agelena labyrinthica</td>\n",
       "      <td>https://arachno.piwigo.com/index?/category/67-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agelenidae</td>\n",
       "      <td>Allagelena</td>\n",
       "      <td>Allagelena gracilens</td>\n",
       "      <td>https://arachno.piwigo.com/index?/category/68-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agelenidae</td>\n",
       "      <td>Aterigena</td>\n",
       "      <td>Aterigena ligurica</td>\n",
       "      <td>https://arachno.piwigo.com/index?/category/143...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agelenidae</td>\n",
       "      <td>Aterigena</td>\n",
       "      <td>Aterigena soriculata</td>\n",
       "      <td>https://arachno.piwigo.com/index?/category/159...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       family       genus               species  \\\n",
       "0  Agelenidae     Agelena   Agelena agelenoides   \n",
       "1  Agelenidae     Agelena  Agelena labyrinthica   \n",
       "2  Agelenidae  Allagelena  Allagelena gracilens   \n",
       "3  Agelenidae   Aterigena    Aterigena ligurica   \n",
       "4  Agelenidae   Aterigena  Aterigena soriculata   \n",
       "\n",
       "                                                link  \n",
       "0  https://arachno.piwigo.com/index?/category/176...  \n",
       "1  https://arachno.piwigo.com/index?/category/67-...  \n",
       "2  https://arachno.piwigo.com/index?/category/68-...  \n",
       "3  https://arachno.piwigo.com/index?/category/143...  \n",
       "4  https://arachno.piwigo.com/index?/category/159...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = []\n",
    "\n",
    "for f in tqdm(main_page.li('li')):\n",
    "    genus_info = []\n",
    "    try:\n",
    "        if f['class'][0] == 'liClosed':\n",
    "            family = f.a.getText()\n",
    "            for g in f('li'):\n",
    "                genus_arr = g.a.getText().split(' ')\n",
    "                genus = genus_arr[0]\n",
    "                \n",
    "                species = genus\n",
    "                if len(genus_arr) > 1:\n",
    "                    species = genus + ' ' + ' '.join(genus_arr[1:])\n",
    "                \n",
    "                species_link = base_url + f'{g.a[\"href\"]}' \n",
    "                \n",
    "                info.append([family, genus, species, species_link])\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "info = np.array(info)\n",
    "\n",
    "df = pd.DataFrame(info, columns=['family', 'genus', 'species', 'link'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1465, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('data/spiderbase_0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/spiderbase_0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1465, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_images(img_content, species):\n",
    "    groups = {'general': [], 'epigyne': [], 'palpe': [], 'vulve': [], 'other': []}\n",
    "    for img in img_content:\n",
    "        name = img['name'].lower()\n",
    "        if 'epigyne' in name:\n",
    "            groups['epigyne'].append(img)\n",
    "        elif 'palpe' in name:\n",
    "            groups['palpe'].append(img)\n",
    "        elif 'vulve' in name:\n",
    "            groups['vulve'].append(img)\n",
    "        elif name == species.lower():\n",
    "            groups['general'].append(img)\n",
    "        else:\n",
    "            groups['other'].append(img)\n",
    "    return groups\n",
    "\n",
    "# def get_image_metainfo(args):\n",
    "#     url, species_name = args\n",
    "#     img_content = []\n",
    "#     sleep(1)\n",
    "#     try:\n",
    "#         img_data = get_soup_simple(url, 'ul', {'class':'thumbnails', 'id':\"thumbnails\"})('span', 'wrap2')\n",
    "#         for dt in img_data:\n",
    "#             sleep(1)\n",
    "#             img_site_link = base_url+dt.a['href']\n",
    "#             name = dt.img.attrs['alt']\n",
    "#             credits = dt.img.attrs['title']\n",
    "#             main_image = get_soup_simple(img_site_link, 'img', {'id': 'theMainImage'}).img\n",
    "#             link = base_url+main_image.attrs['src']\n",
    "#             image = io.imread(link)\n",
    "#             img_content.append({'name': name, 'image': image , 'credits': credits})\n",
    "\n",
    "#         groups = group_images(img_content, species_name)\n",
    "#         #pickle.dump(groups, open(f'data/image_data/{species_name.replace(\" \",\"-\").lower()}.pkl','wb'))\n",
    "#         print('fix this')\n",
    "#         return True, args, ''\n",
    "#     except Exception as e:\n",
    "#         return False, args, e\n",
    "    \n",
    "def get_image_metainfo_quick(args):\n",
    "    url, species_name = args\n",
    "    img_content = []\n",
    "    sleep(1)\n",
    "    try:\n",
    "        img_data = get_soup_simple(url, 'ul', {'class':'thumbnails', 'id':\"thumbnails\"})('span', 'wrap2')\n",
    "        for dt in img_data:\n",
    "            sleep(0.1)\n",
    "            name = dt.img.attrs['alt']\n",
    "            credits = dt.img.attrs['title']\n",
    "            link = base_url+dt.img['src']\n",
    "            image = io.imread(link)\n",
    "            img_content.append({'name': name, 'image': image , 'credits': credits})\n",
    "\n",
    "        groups = group_images(img_content, species_name)\n",
    "        with open(f'data/image_data_0/{species_name.replace(\" \",\"-\").lower()}.pkl','wb') as out_file:\n",
    "            pickle.dump(groups, out_file)\n",
    "        return True, args, ''\n",
    "    except Exception as e:\n",
    "        return False, args, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove data which is deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_data = glob('data/image_data_0/*.pkl')\n",
    "updated_data = [f'data/image_data_0/{species_name.replace(\" \",\"-\").lower()}.pkl' for species_name in df.species]\n",
    "\n",
    "for data in existing_data:\n",
    "    if data not in updated_data:\n",
    "        print(f'Deleting {data}')\n",
    "        os.system(f'rm -rf {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download any new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bafc8abfe44e23923b8f1d64ec7dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1465.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: Erigone\n",
      "Downloading: Meioneta\n",
      "Downloading: Oedothorax\n",
      "Downloading: Porrhomma\n",
      "Downloading: Tenuiphantes\n",
      "Downloading: Walckenaeria\n",
      "Downloading: x-Phantes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arg_list= df[['link', 'species']].values.astype(str)\n",
    "\n",
    "results = []\n",
    "for arg in tqdm(arg_list):\n",
    "    species_name = arg[1]\n",
    "    fname = f'data/image_data_0/{species_name.replace(\" \",\"-\").lower()}.pkl'\n",
    "    if not os.path.isfile(fname):\n",
    "        print(f'Downloading: {species_name}')\n",
    "        results.append(get_image_metainfo_quick(arg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-download updated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_update = '19-03-2020'\n",
    "latest_update = datetime.strptime(latest_update, '%d-%m-%Y').date()\n",
    "\n",
    "today = datetime.today().date()\n",
    "\n",
    "def get_update_page(date):\n",
    "    return f'https://arachno.piwigo.com/index?/category/familles/posted-monthly-list-{date.year}-{date.month}-{date.day}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parsed pages: 1\n",
      "Number of parsed pages: 2\n"
     ]
    }
   ],
   "source": [
    "dates = []\n",
    "species = []\n",
    "\n",
    "all_updates = False\n",
    "i = 0\n",
    "\n",
    "while not all_updates:\n",
    "    if latest_update == today:\n",
    "        break\n",
    "        \n",
    "    if i == 0:\n",
    "        date = today\n",
    "    \n",
    "    sleep(1)\n",
    "    data = get_soup_simple(get_update_page(date))\n",
    "    print(f'Number of parsed pages: {i+1}')\n",
    "    \n",
    "    try:\n",
    "        species.extend([x['alt'].split('-')[0].rstrip() for x in data('ul', 'thumbnails')[0]('img')])\n",
    "    except:\n",
    "        None\n",
    "    link = base_url+data('div', 'calendarBar')[0].div.a['href']\n",
    "    prev_date = datetime.strptime('-'.join(link.split('-')[-3:]), '%Y-%m-%d').date()\n",
    "\n",
    "    if prev_date < latest_update:\n",
    "        all_updates = True\n",
    "    else:\n",
    "        date = prev_date\n",
    "        i += 1\n",
    "    \n",
    "species = [x for x in species if len(x.split(' ')) <= 3]\n",
    "species = np.unique(species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f3b680290740d7a51259ae4a8e44de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: Zelotes egregioides\n",
      "Downloading: Peponocranium ludicrum\n",
      "Downloading: Argyrodes argyrodes\n",
      "Downloading: Coleosoma floridanum\n",
      "Downloading: Cryptachaea blattea\n",
      "Downloading: Kochiura aulica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arg_list_update = df[df.species.isin(species)][['link', 'species']].values.astype(str)\n",
    "\n",
    "results = []\n",
    "for arg in tqdm(arg_list_update):\n",
    "    print(f'Updating: {arg[1]}')\n",
    "    results.append(get_image_metainfo_quick(arg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
